package com.nickcoblentz.kubepentest.commands

import com.github.ajalt.clikt.core.CliktCommand
import com.github.ajalt.clikt.core.installMordantMarkdown
import com.github.ajalt.clikt.core.requireObject
import com.github.ajalt.clikt.parameters.options.default
import com.github.ajalt.clikt.parameters.options.option
import com.github.ajalt.clikt.parameters.options.required
import com.github.ajalt.clikt.parameters.types.choice
import com.github.ajalt.clikt.parameters.types.long
import com.github.ajalt.mordant.rendering.TextColors
import com.nickcoblentz.data.DataSerializer
import com.nickcoblentz.kubepentest.models.KubePentestContext
import com.nickcoblentz.kubepentest.utils.coorelateNmapResultsWithKubernetesResources
import com.nickcoblentz.kubepentest.utils.parseNmapXml
import io.fabric8.kubernetes.api.model.Pod
import io.fabric8.kubernetes.api.model.batch.v1.Job
import io.fabric8.kubernetes.client.Watcher
import io.fabric8.kubernetes.client.WatcherException
import org.w3c.dom.Element
import java.nio.file.Files
import java.nio.file.Path
import java.time.Duration
import java.time.LocalDateTime
import java.time.format.DateTimeFormatter
import java.util.concurrent.atomic.AtomicBoolean
import java.util.concurrent.atomic.AtomicReference
import javax.xml.parsers.DocumentBuilderFactory
import kotlin.io.path.Path
import kotlin.io.path.absolutePathString
import kotlin.io.path.exists
import kotlin.io.path.writeText

/**
 * Command to perform an nmap scan inside the kubernetes cluster by launching a kubernetes job.
 */

enum class ScanType(val type : String) {
    NODES("nodes"),
    PODS("pods"),
    SERVICES("services"),
    CUSTOM("custom");

}

class NmapScan : CliktCommand() {
    override fun help(context: com.github.ajalt.clikt.core.Context) =
        "${(TextColors.green)("(online)")} Perform an nmap scan inside the kubernetes cluster"

    private val config by requireObject<KubePentestContext>()

    private val namespaceOption by option("-n", "--namespace", help = "Namespace to deploy the nmap job to").required()
    private val jobTemplateOption by option("-j", "--job-template", help = "Job template file")



    private val scanTypeOption by option("--scan-type","-s", help = "Scan type")
        .choice(
            ScanType.NODES.type,
            ScanType.PODS.type,
            ScanType.SERVICES.type,
            ScanType.CUSTOM.type)
        .default(ScanType.NODES.type)
    private val customIPRangeOption by option("--custom-ip-range","-r", help = "Custom IP range to scan ex: \"10.10.0.1 10.10.0.4 192.168.8.8\" ")
    private val portRangeOption by option("--custom-port-range","-p", help = "Custom Port range to scan ex: \"0-65535\" or \"80,443,8080-8085\"").default("0-65535")
    private val nmapOptions by option("--options", help="Nmap options to use. ex: \"--open -T4 -Pn -A\"").default("--open -T4 -Pn -A")
    private val timeoutOption by option("--timeout", help="Timeout for the nmap scan in minutes. Default is 240 minutes").long().default(240)



    init {
        this.installMordantMarkdown()
    }

    override fun run() {
        // Ensure directories exist (including nmap directory)
        config.ensureDirectoriesExist()

        // Determine which IPs to scan
        val ipsToScan : String = when (scanTypeOption) {
            ScanType.NODES.type -> readIpsFromFile(config.ipsDataDirectoryPath("nodeips.txt"))
            ScanType.PODS.type -> readIpsFromFile(config.ipsDataDirectoryPath("podips.txt"))
            ScanType.SERVICES.type -> readIpsFromFile(config.ipsDataDirectoryPath("serviceips.txt"))
            else -> {
                if(customIPRangeOption.isNullOrBlank()) {
                    config.prettyLogger.printlnError(title = "Error", message = "No IP range specified. Use --custom-ip-range")
                    ""
                }
                else
                    customIPRangeOption.toString().trim()

            }
        }

        if (ipsToScan.isBlank()) {
            config.prettyLogger.printlnError(title = "Error", message = "No IPs found to scan")
            return
        }

        // Load job template
        val jobPath : Path = jobTemplateOption?.let { Path(it) } ?: config.testCaseDirectoryPath("job-template.yaml")
        if (!jobPath.exists()) {
            config.prettyLogger.printlnError(title = "Error", message = "Job template file not found: ${jobPath.absolutePathString()}")
            return
        }

        config.prettyLogger.printlnInfo(message = "Loading ${jobPath.absolutePathString()}")
        val jobTemplateYaml = Files.readString(jobPath)

        // Create and run the nmap job
        val outputFilename = "nmap-results-$scanTypeOption-${LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd-HHmmss"))}.xml"
        val outputFilePath = config.nmapDirectoryPath(outputFilename)
        val logsFilename = "nmap-logs-$scanTypeOption-${LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd-HHmmss"))}.txt"
        val logsFilePath = config.nmapDirectoryPath(logsFilename)

        val coorelatedFilePrefix = "nmap-coorelated-$scanTypeOption-${LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd-HHmmss"))}"

        runNmapJob(jobTemplateYaml, ipsToScan, portRangeOption,nmapOptions, outputFilePath, logsFilePath,coorelatedFilePrefix)
    }

    private fun readIpsFromFile(filePath: Path): String {
        if (!filePath.exists()) {
            config.prettyLogger.printlnWarning(title = "Warning", message = "IP file not found: ${filePath.absolutePathString()}")
            return ""
        }

        return Files.readAllLines(filePath)
            .filter { it.isNotBlank() }.joinToString(" ") { it.trim() }
    }

    private fun runNmapJob(jobTemplateYaml: String, targetHosts: String, targetPorts: String, nmapExtraOptions : String, outputFilePath: Path, logsFilePath : Path, coorelatedFilePrefix : String) {
        val jobName = "nmap-scan-${System.currentTimeMillis()}"

        // Modify the job template to run nmap
        val job = config.k8s.batch().v1().jobs().load(jobTemplateYaml.byteInputStream()).item()
        job.metadata.name = jobName

        val approximateHostCount = targetHosts.split(" ").size
        config.prettyLogger.printlnInfo(title = "Nmap Scan", message = "Preparing to scan approximately $approximateHostCount hosts")

        // Add a volume for storing results
        val resultsVolumeName = "nmap-results-volume"
        val resultsVolumeMountPath = "/results"

        // Add the volume to the pod spec
        val emptyDirVolume = io.fabric8.kubernetes.api.model.Volume()
        emptyDirVolume.name = resultsVolumeName
        emptyDirVolume.emptyDir = io.fabric8.kubernetes.api.model.EmptyDirVolumeSource()
        job.spec.template.spec.volumes.add(emptyDirVolume)

        // Add the volume mount to the container
        val volumeMount = io.fabric8.kubernetes.api.model.VolumeMount()
        volumeMount.name = resultsVolumeName
        volumeMount.mountPath = resultsVolumeMountPath
        job.spec.template.spec.containers[0].volumeMounts.add(volumeMount)

        // Set the command to run nmap with XML output and progress tracking
        val nmapCommand = """
           | echo "Starting nmap scan of $approximateHostCount hosts..." &&
           | mkdir -p $resultsVolumeMountPath &&
           | nmap $nmapExtraOptions -p$portRangeOption -oN - -oX $resultsVolumeMountPath/nmap-results.xml $targetHosts &&           
           | echo "Nmap scan complete. Results saved to $resultsVolumeMountPath/nmap-results.xml" &&
           | sleep 20s
        """.trimMargin()
        job.spec.template.spec.containers[0].command = listOf("bash", "-c", nmapCommand)

        config.prettyLogger.printlnInfo(title = "Nmap Job", message = "Creating job $jobName")

        // State variables for monitoring
        val jobCompleted = AtomicBoolean(false)
        val jobSucceeded = AtomicBoolean(false)
        val jobFailureReason = AtomicReference<String?>(null)
        val nmapResults = AtomicReference<String?>(null)
        val nmapLogs = AtomicReference<String?>(null)

        try {
            // Create the job
            val createdJob = config.k8s.batch().v1().jobs().inNamespace(namespaceOption).resource(job).create()
            config.prettyLogger.printlnInfo(message = "Job '$jobName' deployed. Waiting for completion...")

            // Set up a watcher for the job
            val jobWatcher = object : Watcher<Job> {
                override fun eventReceived(action: Watcher.Action, resource: Job) {
                    if (resource.metadata.name == jobName) {
                        val status = resource.status
                        if (status != null) {
                            if (status.succeeded != null && status.succeeded > 0) {
                                config.prettyLogger.printlnInfo(message = "Job '$jobName' succeeded.")
                                jobSucceeded.set(true)
                                jobCompleted.set(true)
                            } else if (status.failed != null && status.failed > 0) {
                                val reason = "Job failed with ${status.failed} failures"
                                config.prettyLogger.printlnError(title = "Job '$jobName' failed", message = reason)
                                config.prettyLogger.printlnError(message = config.importExportUtils.serializeToYamlString(resource))
                                config.prettyLogger.printlnError(title = "Job logs:\n",config.k8s.pods()
                                    .inNamespace(namespaceOption)
                                    .withName(resource.metadata.name)
                                    .log)
                                jobFailureReason.set(reason)
                                jobCompleted.set(true)
                            }
                        }
                    }
                }

                override fun onClose(cause: WatcherException?) {
                    if (cause != null) {
                        config.prettyLogger.printlnError(message = "Job Watcher closed with exception: ${cause.message}")
                        jobCompleted.set(true)
                        jobSucceeded.set(false)
                        jobFailureReason.set("Watcher closed unexpectedly: ${cause.message}")
                    }
                }
            }

            // Start a thread to monitor the job
            val monitorThread = Thread.startVirtualThread {
                config.k8s.batch().v1().jobs().inNamespace(namespaceOption).withName(jobName).watch(jobWatcher).use { watcher ->
                    val startTime = System.currentTimeMillis()
                    val timeout = Duration.ofMinutes(timeoutOption).toMillis()
                    var obtainedResults = false
                    // Wait for job to complete or timeout
                    while (!jobCompleted.get() && (System.currentTimeMillis() - startTime) < timeout) {
                        Thread.sleep(5000)
                        var pods : MutableList<Pod>? = null

                        try {
                            // Get the pod associated with the job
                            pods = config.k8s.pods().inNamespace(namespaceOption)
                                .withLabel("job-name", jobName)
                                .list()
                                .items
                        }
                        catch (e : Exception)
                        {
                            config.prettyLogger.printlnError(title = "Temporary error", message = "Failed to retrieve pods associated with job: ${e.message}\n${e.stackTraceToString()}")
                        }


                        if (!pods.isNullOrEmpty()) {
                            val pod = pods[0]

                            // Print pod logs
                            try {
                                val logs = config.k8s.pods()
                                    .inNamespace(namespaceOption)
                                    .withName(pod.metadata.name)
                                    .log
                                // Update progress indicator based on logs
                                val completedHosts = logs.lines().filter { it.contains("Nmap scan report for") || it.contains("Failed to resolve")}.size
                                config.prettyLogger.printlnInfo(title="Progress","$completedHosts/$approximateHostCount hosts completed")
                                if(!obtainedResults && logs.contains("Nmap scan complete. Results saved to")) {
                                    try {
                                        val results = config.k8s.pods()
                                            .inNamespace(namespaceOption)
                                            .withName(pod.metadata.name)
                                            .inContainer("test-container")
                                            .file("/results/nmap-results.xml")
                                            .read()
                                            .readAllBytes()
                                            .toString(Charsets.UTF_8)
                                        nmapResults.set(results)
                                        nmapLogs.set(logs)
                                        obtainedResults=true
                                    } catch (e: Exception) {
                                        config.prettyLogger.printlnError(title = "Error", message = "Failed to retrieve nmap results: ${e.message}")
                                    }
                                }

                            } catch (e: Exception) {
                                // Ignore log retrieval errors
                            }
                        }
                    }


                    watcher.close()

                    if (!jobCompleted.get()) {
                        config.prettyLogger.printlnError(title = "Timeout", message = "Job did not complete within the timeout period")
                        jobFailureReason.set("Timeout")
                        jobCompleted.set(true)
                    }
                }
            }


            // Wait for the monitor thread to complete
            monitorThread.join()

            // Save the nmap results to a file if available
            val results = nmapResults.get()
            if (results != null) {
                Files.writeString(outputFilePath, results)
                config.prettyLogger.printlnSuccess(title = "Nmap Scan", message = "Results saved to ${outputFilePath.absolutePathString()}")

                val deserializeResources =
                    config.importExportUtils.deserializeFromFile(config.allJSONFilePath().toString())


                val nmapKubeEntries = parseNmapXml(results)
                coorelateNmapResultsWithKubernetesResources(nmapKubeEntries, deserializeResources, config.importExportUtils)

                var coorelatedPath = config.nmapDirectoryPath(coorelatedFilePrefix + ".json")
                coorelatedPath.writeText(DataSerializer.toJson(nmapKubeEntries))
                config.prettyLogger.printlnSuccess(title = "Nmap Scan", message = "Coorelated results saved to ${coorelatedPath.absolutePathString()}")

                coorelatedPath = config.nmapDirectoryPath(coorelatedFilePrefix + ".csv")
                coorelatedPath.writeText(DataSerializer.toCsv(nmapKubeEntries))
                config.prettyLogger.printlnSuccess(title = "Nmap Scan", message = "Coorelated results saved to ${coorelatedPath.absolutePathString()}")

                coorelatedPath = config.nmapDirectoryPath(coorelatedFilePrefix + ".md")
                coorelatedPath.writeText("# Coorelated Results\n"+DataSerializer.toMarkdownTable(nmapKubeEntries))
                config.prettyLogger.printlnSuccess(title = "Nmap Scan", message = "Coorelated results saved to ${coorelatedPath.absolutePathString()}")


            } else {
                config.prettyLogger.printlnError(title = "Nmap Scan", message = "No results were obtained")
            }


            // Save the nmap results to a file if available
            val logs = nmapLogs.get()
            if (logs != null) {
                Files.writeString(logsFilePath, logs)
                config.prettyLogger.printlnSuccess(title = "Nmap logs", message = "Results saved to ${logsFilePath.absolutePathString()}")
            } else {
                config.prettyLogger.printlnError(title = "Nmap logs", message = "No results were obtained")
            }





        } catch (e: Exception) {
            config.prettyLogger.printlnError(title = "Error", message = "Failed to create or monitor job: ${e.message}")
        } finally {
            // Clean up the job
            try {
                config.k8s.batch().v1().jobs().inNamespace(namespaceOption).withName(jobName).delete()
                config.prettyLogger.printlnInfo(message = "Job '$jobName' deleted")
            } catch (e: Exception) {
                config.prettyLogger.printlnWarning(title = "Warning", message = "Failed to delete job: ${e.message}")
            }
        }
    }
}
